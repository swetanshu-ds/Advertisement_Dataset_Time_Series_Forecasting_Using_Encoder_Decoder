{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f7e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4398ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket='training-data-lstm', Key = 'processed_training_data.csv')\n",
    "dataset = pd.read_csv(obj['Body'], nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d1cb9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_data_desc_order = dataset[\"keywordId\"].value_counts(ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d12be998",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==0 or i%16==15]\n",
    "list_2 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==1 or i%16==14]\n",
    "list_3 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==2 or i%16==13]\n",
    "list_4 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==3 or i%16==12]\n",
    "list_5 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==4 or i%16==11]\n",
    "list_6 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==5 or i%16==10]\n",
    "list_7 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==6 or i%16==9]\n",
    "list_8 = [keyword_data_desc_order[i] for i in range(len(keyword_data_desc_order)) if i%16==7 or i%16==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d443a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_1 = dataset.loc[dataset[\"keywordId\"].isin(list_1)]\n",
    "shard_2 = dataset.loc[dataset[\"keywordId\"].isin(list_2)]\n",
    "shard_3 = dataset.loc[dataset[\"keywordId\"].isin(list_3)]\n",
    "shard_4 = dataset.loc[dataset[\"keywordId\"].isin(list_4)]\n",
    "shard_5 = dataset.loc[dataset[\"keywordId\"].isin(list_5)]\n",
    "shard_6 = dataset.loc[dataset[\"keywordId\"].isin(list_6)]\n",
    "shard_7 = dataset.loc[dataset[\"keywordId\"].isin(list_7)]\n",
    "shard_8 = dataset.loc[dataset[\"keywordId\"].isin(list_8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b9a7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_1.to_csv(\"shard_1_small.csv\", index=False)\n",
    "shard_2.to_csv(\"shard_2_small.csv\", index=False)\n",
    "shard_3.to_csv(\"shard_3_small.csv\", index=False)\n",
    "shard_4.to_csv(\"shard_4_small.csv\", index=False)\n",
    "shard_5.to_csv(\"shard_5_small.csv\", index=False)\n",
    "shard_6.to_csv(\"shard_6_small.csv\", index=False)\n",
    "shard_7.to_csv(\"shard_7_small.csv\", index=False)\n",
    "shard_8.to_csv(\"shard_8_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad8db61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file(\"shard_1_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af8dceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.meta.client.upload_file(\"shard_2_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_2.csv')\n",
    "s3.meta.client.upload_file(\"shard_3_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_3.csv')\n",
    "s3.meta.client.upload_file(\"shard_4_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_4.csv')\n",
    "s3.meta.client.upload_file(\"shard_5_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_5.csv')\n",
    "s3.meta.client.upload_file(\"shard_6_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_6.csv')\n",
    "s3.meta.client.upload_file(\"shard_7_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_7.csv')\n",
    "s3.meta.client.upload_file(\"shard_8_small.csv\", 'training-data-lstm', 'sharded_data_small/shard_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69584c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py \n",
    "\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "HISTORICAL_DATA_WINDOW = 14\n",
    "FUTURE_PREDICTION_WINDOW = 3\n",
    "\n",
    "save_bucket_name = \"\"\n",
    "\n",
    "def create_training_frames(partition, keywordId):\n",
    "\n",
    "  partition.sort_values(by=[\"date\"], inplace=True)\n",
    "  split_index = keywordId\n",
    "    \n",
    "  train_frames_X, train_frames_Y = [], []\n",
    "  test_frames_X, test_frames_Y = [], []\n",
    "  train_frames_embed, test_frames_embed = [], []\n",
    "  train_frames_decoder_input, test_frames_decoder_input = [], []\n",
    "\n",
    "  train_size = (int)(len(partition) * 0.7)\n",
    "  train_data = partition[:train_size]\n",
    "  test_data = partition[train_size-HISTORICAL_DATA_WINDOW-FUTURE_PREDICTION_WINDOW+1:]\n",
    "  data_columns = partition.columns\n",
    "\n",
    "  train_data_arr, test_data_arr = np.array(train_data), np.array(test_data)\n",
    "  if train_data_arr.shape[0] < HISTORICAL_DATA_WINDOW or test_data_arr.shape[0] < HISTORICAL_DATA_WINDOW:\n",
    "    return 0\n",
    "    \n",
    "  train_data_frame_X = sliding_window_view(train_data_arr, window_shape = (HISTORICAL_DATA_WINDOW, train_data_arr.shape[1]))\n",
    "  test_data_frame_X = sliding_window_view(test_data_arr, window_shape = (HISTORICAL_DATA_WINDOW, test_data_arr.shape[1]))\n",
    "  train_data_frame_X = np.squeeze(train_data_frame_X)[:-FUTURE_PREDICTION_WINDOW]\n",
    "  test_data_frame_X = np.squeeze(test_data_frame_X)[:-FUTURE_PREDICTION_WINDOW]\n",
    "  train_data_frames_X, test_data_frames_X = train_data_frame_X.copy(), test_data_frame_X.copy()\n",
    "  for frame in train_data_frames_X:\n",
    "    train_frames_X.append(pd.DataFrame(frame, columns=data_columns))\n",
    "  for frame in test_data_frames_X:\n",
    "    test_frames_X.append(pd.DataFrame(frame, columns=data_columns))\n",
    "\n",
    "  train_data_frame_Y = sliding_window_view(train_data_arr, window_shape = (FUTURE_PREDICTION_WINDOW, train_data_arr.shape[1]))\n",
    "  test_data_frame_Y = sliding_window_view(test_data_arr, window_shape = (FUTURE_PREDICTION_WINDOW, test_data_arr.shape[1]))\n",
    "  train_data_frame_Y = np.squeeze(train_data_frame_Y)[HISTORICAL_DATA_WINDOW:]\n",
    "  test_data_frame_Y = np.squeeze(test_data_frame_Y)[HISTORICAL_DATA_WINDOW:]\n",
    "  train_data_frames_Y, test_data_frames_Y = train_data_frame_Y.copy(), test_data_frame_Y.copy()\n",
    "  for frame in train_data_frames_Y:\n",
    "    train_frames_Y.append(pd.DataFrame(frame, columns=data_columns))\n",
    "  for frame in test_data_frames_Y:\n",
    "    test_frames_Y.append(pd.DataFrame(frame, columns=data_columns))\n",
    "    \n",
    "  embedding_columns = [\"keyword_length\", \"keyword_num_words\", \"budget\", \"matchType\", \"country_code\", \"campaign_type\", \"targeting_type\", \"budget_type\", \"adFormat\", \"tactic\", \"costType\"]\n",
    "  \n",
    "  for i in range(len(train_frames_X)):\n",
    "    train_frames_embed.append(train_frames_X[i].loc[0][embedding_columns])\n",
    "    train_frames_X[i].drop(columns=embedding_columns, inplace=True)\n",
    "\n",
    "  for i in range(len(test_frames_X)):\n",
    "    test_frames_embed.append(test_frames_X[i].loc[0][embedding_columns])\n",
    "    test_frames_X[i].drop(columns=embedding_columns, inplace=True)\n",
    "    \n",
    "  for i in range(len(train_frames_X)):\n",
    "    train_frames_X[i].drop(columns=[\"keywordId\", \"date\"], inplace=True)\n",
    "    train_frames_Y[i].drop(columns=embedding_columns, inplace=True)\n",
    "    train_frames_Y[i].drop(columns=[\"keywordId\", \"date\", \"year\", \"month\", \"day\", \"dayoftheweek\", \"clicks\", \"impressions\", \"orders\", \"campaign_sales_perc\", \"campaign_spend_perc\", \"account_sales_perc\", \"account_spend_perc\"], inplace=True)\n",
    "\n",
    "  for i in range(len(test_frames_X)):\n",
    "    test_frames_X[i].drop(columns=[\"keywordId\", \"date\"], inplace=True)\n",
    "    test_frames_Y[i].drop(columns=embedding_columns, inplace=True)\n",
    "    test_frames_Y[i].drop(columns=[\"keywordId\", \"date\", \"year\", \"month\", \"day\", \"dayoftheweek\", \"clicks\", \"impressions\", \"orders\", \"campaign_sales_perc\", \"campaign_spend_perc\", \"account_sales_perc\", \"account_spend_perc\"], inplace=True)\n",
    "  \n",
    "  for i in range(len(train_frames_Y)):\n",
    "      train_frames_decoder_input.append(train_frames_Y[i][\"cpc\"])\n",
    "      train_frames_Y[i].drop(columns=[\"cpc\"], inplace=True)\n",
    "\n",
    "  for i in range(len(test_frames_Y)):\n",
    "      test_frames_decoder_input.append(test_frames_Y[i][\"cpc\"])\n",
    "      test_frames_Y[i].drop(columns=[\"cpc\"], inplace=True)\n",
    "    \n",
    "  train_frames_X, train_frames_Y = np.array(train_frames_X), np.array(train_frames_Y)\n",
    "  test_frames_X, test_frames_Y = np.array(test_frames_X), np.array(test_frames_Y)\n",
    "  train_frames_embed, test_frames_embed = np.array(train_frames_embed), np.array(test_frames_embed)\n",
    "  train_frames_decoder_input, test_frames_decoder_input = np.array(train_frames_decoder_input), np.array(test_frames_decoder_input)\n",
    "  \n",
    "  train_frames_x_dir = \"./train_frames_x\"\n",
    "  test_frames_x_dir = \"./test_frames_x\"\n",
    "  train_frames_y_dir = \"./train_frames_y\"\n",
    "  test_frames_y_dir = \"./test_frames_y\"\n",
    "  train_frames_embed_dir = \"./train_frames_embed\"\n",
    "  test_frames_embed_dir = \"./test_frames_embed\"\n",
    "  train_frames_decoder_input_dir = \"./train_frames_decoder_input\"\n",
    "  test_frames_decoder_input_dir = \"./test_frames_decoder_input\"\n",
    "  \n",
    "  if not os.path.exists(train_frames_x_dir):\n",
    "    os.makedirs(train_frames_x_dir)\n",
    "  if not os.path.exists(test_frames_x_dir):\n",
    "    os.makedirs(test_frames_x_dir)\n",
    "  if not os.path.exists(train_frames_y_dir):\n",
    "    os.makedirs(train_frames_y_dir)\n",
    "  if not os.path.exists(test_frames_y_dir):\n",
    "    os.makedirs(test_frames_y_dir)\n",
    "  if not os.path.exists(train_frames_embed_dir):\n",
    "    os.makedirs(train_frames_embed_dir)\n",
    "  if not os.path.exists(test_frames_embed_dir):\n",
    "    os.makedirs(test_frames_embed_dir)\n",
    "  if not os.path.exists(train_frames_decoder_input_dir):\n",
    "    os.makedirs(train_frames_decoder_input_dir)\n",
    "  if not os.path.exists(test_frames_decoder_input_dir):\n",
    "    os.makedirs(test_frames_decoder_input_dir)\n",
    "    \n",
    "  np.save(os.path.join(train_frames_x_dir, f\"par_{split_index}.npy\"), train_frames_X)\n",
    "  np.save(os.path.join(test_frames_x_dir, f\"par_{split_index}.npy\"), test_frames_X)\n",
    "  np.save(os.path.join(train_frames_y_dir, f\"par_{split_index}.npy\"), train_frames_Y)\n",
    "  np.save(os.path.join(test_frames_y_dir, f\"par_{split_index}.npy\"), test_frames_Y)\n",
    "  np.save(os.path.join(train_frames_embed_dir, f\"par_{split_index}.npy\"), train_frames_X)\n",
    "  np.save(os.path.join(test_frames_embed_dir, f\"par_{split_index}.npy\"), test_frames_X)\n",
    "  np.save(os.path.join(train_frames_decoder_input_dir, f\"par_{split_index}.npy\"), train_frames_Y)\n",
    "  np.save(os.path.join(test_frames_decoder_input_dir, f\"par_{split_index}.npy\"), test_frames_Y)\n",
    "\n",
    "  return 0\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    for file in Path(\"/opt/ml/processing/input/\").rglob('*.csv'):\n",
    "      file_path = str(file)\n",
    "      dataset = pd.read_csv(file_path)\n",
    "      for keyword in dataset[\"keywordId\"].unique():\n",
    "        val = create_training_frames(dataset.loc[dataset[\"keywordId\"]==keyword], keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95e115bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sagemaker_logger = logging.getLogger(\"sagemaker\")\n",
    "sagemaker_logger.setLevel(logging.INFO)\n",
    "sagemaker_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto3.session.Session(region_name='eu-north-1'))\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20e14657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu-north-1'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11c18ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chmod 777 lost+found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192258a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:Uploaded /home/ec2-user/SageMaker/ to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/sourcedir.tar.gz\n",
      "runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-eu-north-1-321097665711/preprocessing-2023-07-11-14-52-48-747/source/runproc.sh\n",
      "Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n",
      "Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n",
      "Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n",
      "Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n",
      "Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n",
      "Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n",
      "Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n",
      "INFO:sagemaker:Creating processing-job with name preprocessing-2023-07-11-14-52-48-747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................\u001b[34mFound existing installation: typing 3.7.4.3\u001b[0m\n",
      "\u001b[34mUninstalling typing-3.7.4.3:\n",
      "  Successfully uninstalled typing-3.7.4.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.20\n",
      "  Downloading numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.3/15.3 MB 17.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.19.5\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 1.0 requires numpy==1.19.5, but you have numpy 1.20.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed numpy-1.20.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mpreprocess.py:18: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partition.sort_values(by=[\"date\"], inplace=True)\u001b[0m\n",
      "\u001b[35mFound existing installation: typing 3.7.4.3\u001b[0m\n",
      "\u001b[35mUninstalling typing-3.7.4.3:\n",
      "  Successfully uninstalled typing-3.7.4.3\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mCollecting numpy==1.20\n",
      "  Downloading numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\u001b[0m\n",
      "\u001b[35m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.3/15.3 MB 17.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\u001b[0m\n",
      "\u001b[35m      Successfully uninstalled numpy-1.19.5\u001b[0m\n",
      "\u001b[32mFound existing installation: typing 3.7.4.3\u001b[0m\n",
      "\u001b[32mUninstalling typing-3.7.4.3:\n",
      "  Successfully uninstalled typing-3.7.4.3\u001b[0m\n",
      "\u001b[32mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mFound existing installation: typing 3.7.4.3\u001b[0m\n",
      "\u001b[34mUninstalling typing-3.7.4.3:\n",
      "  Successfully uninstalled typing-3.7.4.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.20\n",
      "  Downloading numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.3/15.3 MB 13.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting numpy==1.20\n",
      "  Downloading numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\u001b[0m\n",
      "\u001b[32m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.3/15.3 MB 25.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\u001b[0m\n",
      "\u001b[32m      Successfully uninstalled numpy-1.19.5\u001b[0m\n",
      "\u001b[36mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[36msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[36msagemaker-sklearn-container 1.0 requires numpy==1.19.5, but you have numpy 1.20.0 which is incompatible.\u001b[0m\n",
      "\u001b[36mSuccessfully installed numpy-1.20.0\u001b[0m\n",
      "\u001b[36mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mpreprocess.py:18: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[36mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
      "\u001b[36mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partition.sort_values(by=[\"date\"], inplace=True)\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 1.0 requires numpy==1.19.5, but you have numpy 1.20.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed numpy-1.20.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[32mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[32msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[32msagemaker-sklearn-container 1.0 requires numpy==1.19.5, but you have numpy 1.20.0 which is incompatible.\u001b[0m\n",
      "\u001b[32mSuccessfully installed numpy-1.20.0\u001b[0m\n",
      "\u001b[32mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mpreprocess.py:18: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partition.sort_values(by=[\"date\"], inplace=True)\u001b[0m\n",
      "\u001b[32mpreprocess.py:18: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[32mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
      "\u001b[32mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partition.sort_values(by=[\"date\"], inplace=True)\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 30\u001b[0m\n\u001b[1;32m     20\u001b[0m source_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://training-data-lstm/sharded_data_small/\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# sklearn_processor = SKLearnProcessor(framework_version='0.23-1',\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#                                      role=role,\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#                                      instance_type='ml.t3.medium',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#                                      sagemaker_session = sagemaker_session\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#                                     )\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mscript_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocess.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ec2-user/SageMaker/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mProcessingInput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43ms3_data_distribution_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShardedByS3Key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/opt/ml/processing/input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mProcessingOutput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m          \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/opt/ml/processing/output/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://training-data-lstm/processed-sharded-data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m stop \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime: \u001b[39m\u001b[38;5;124m'\u001b[39m, stop \u001b[38;5;241m-\u001b[39m start) \n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/processing.py:1771\u001b[0m, in \u001b[0;36mFrameworkProcessor.run\u001b[0;34m(self, code, source_dir, dependencies, git_config, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m s3_runproc_sh, inputs, job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pack_and_upload_code(\n\u001b[1;32m   1767\u001b[0m     code, source_dir, dependencies, git_config, job_name, inputs, kms_key\n\u001b[1;32m   1768\u001b[0m )\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;66;03m# Submit a processing job.\u001b[39;00m\n\u001b[0;32m-> 1771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_runproc_sh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/processing.py:688\u001b[0m, in \u001b[0;36mScriptProcessor.run\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/processing.py:1113\u001b[0m, in \u001b[0;36mProcessingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Waits for the processing job to complete.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    logs (bool): Whether to show the logs produced by the job (default: True).\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs:\n\u001b[0;32m-> 1113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_processing_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_processing_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:4873\u001b[0m, in \u001b[0;36mSession.logs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE:\n\u001b[1;32m   4871\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 4873\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE:\n\u001b[1;32m   4876\u001b[0m     state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, FrameworkProcessor\n",
    "import timeit\n",
    "\n",
    "est_cls = sagemaker.sklearn.estimator.SKLearn\n",
    "framework_version_str = \"0.20.0\"\n",
    "\n",
    "script_processor = FrameworkProcessor(\n",
    "    role=role,\n",
    "    instance_type='ml.t3.medium',\n",
    "    instance_count=4,\n",
    "    base_job_name = 'preprocessing',\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version=framework_version_str,\n",
    ")\n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "source_folder = \"s3://training-data-lstm/sharded_data_small/\" \n",
    "\n",
    "# sklearn_processor = SKLearnProcessor(framework_version='0.23-1',\n",
    "#                                      role=role,\n",
    "#                                      instance_type='ml.t3.medium',\n",
    "#                                      instance_count=4,\n",
    "#                                      base_job_name = 'preprocessing',\n",
    "#                                      sagemaker_session = sagemaker_session\n",
    "#                                     )\n",
    "\n",
    "script_processor.run(\n",
    "    code='preprocess.py',\n",
    "    source_dir = \"/home/ec2-user/SageMaker/\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=source_folder,\n",
    "            s3_data_distribution_type='ShardedByS3Key',\n",
    "            destination='/opt/ml/processing/input')\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "          source='/opt/ml/processing/output/', \n",
    "          destination='s3://training-data-lstm/processed-sharded-data/'\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "322c45a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4344c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export AWS_DEFAULT_REGION=eu-north-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a49af3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'region'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregion\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'region'"
     ]
    }
   ],
   "source": [
    "role.region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa2723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
