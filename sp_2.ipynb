{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fbcad30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker>2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.173.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (1.26.157)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (1.22.3)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (2.0.1)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (3.5.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>2.0) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.157 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>2.0) (1.29.157)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>2.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>2.0) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker>2.0) (3.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker>2.0) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker>2.0) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker>2.0) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker>2.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker>2.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker>2.0) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>2.0) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>2.0) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>2.0) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>2.0) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker>2.0) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.157->boto3<2.0,>=1.26.131->sagemaker>2.0) (1.26.14)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.173.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.26.157)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.22.3)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.0.1)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.5.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.157 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.157)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.157->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"sagemaker>2.0\"\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb6d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "sagemaker_logger = logging.getLogger(\"sagemaker\")\n",
    "sagemaker_logger.setLevel(logging.INFO)\n",
    "sagemaker_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6afc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"s3://training-data-lstm/processed_training_data.csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab222276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns =  \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac78418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywordId</th>\n",
       "      <th>date</th>\n",
       "      <th>clicks</th>\n",
       "      <th>impressions</th>\n",
       "      <th>orders</th>\n",
       "      <th>budget</th>\n",
       "      <th>campaign_sales_perc</th>\n",
       "      <th>account_sales_perc</th>\n",
       "      <th>campaign_spend_perc</th>\n",
       "      <th>account_spend_perc</th>\n",
       "      <th>...</th>\n",
       "      <th>targeting_type</th>\n",
       "      <th>budget_type</th>\n",
       "      <th>adFormat</th>\n",
       "      <th>tactic</th>\n",
       "      <th>costType</th>\n",
       "      <th>cpc</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayoftheweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45328926266934</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72423678058542</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036826</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        keywordId        date  clicks  impressions  orders  budget   \n",
       "0  45328926266934  2023-01-13       0           37       0   500.0  \\\n",
       "1  72423678058542  2023-01-13       4          131       0   500.0   \n",
       "\n",
       "   campaign_sales_perc  account_sales_perc  campaign_spend_perc   \n",
       "0                  0.0                 0.0             0.000000  \\\n",
       "1                  0.0                 0.0             0.023576   \n",
       "\n",
       "   account_spend_perc  ...  targeting_type  budget_type  adFormat  tactic   \n",
       "0            0.000000  ...               2            0         2       0  \\\n",
       "1            0.013418  ...               2            0         2       0   \n",
       "\n",
       "   costType       cpc  year  month  day  dayoftheweek  \n",
       "0         0  0.000000  2023      1   13             4  \n",
       "1         0  0.036826  2023      1   13             4  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7e3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "HISTORICAL_DATA_WINDOW = 14\n",
    "FUTURE_PREDICTION_WINDOW = 3\n",
    "\n",
    "train_frames_x_dir = \"./train_frames_x\"\n",
    "test_frames_x_dir = \"./test_frames_x\"\n",
    "train_frames_y_dir = \"./train_frames_y\"\n",
    "test_frames_y_dir = \"./test_frames_y\"\n",
    "train_frames_embed_dir = \"./train_frames_embed\"\n",
    "test_frames_embed_dir = \"./test_frames_embed\"\n",
    "train_frames_decoder_input_dir = \"./train_frames_decoder_input\"\n",
    "test_frames_decoder_input_dir = \"./test_frames_decoder_input\"\n",
    "\n",
    "\n",
    "def create_training_frames(key, iterator):\n",
    "    partition = pd.concat(iterator)\n",
    "    partition.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    partition.sort_values(by=[\"date\"], inplace=True)\n",
    "    split_index = partition.iloc[0][\"keywordId\"]\n",
    "    \n",
    "    \n",
    "    train_frames_X, train_frames_Y = [], []\n",
    "    test_frames_X, test_frames_Y = [], []\n",
    "    train_frames_embed, test_frames_embed = [], []\n",
    "    train_frames_decoder_input, test_frames_decoder_input = [], []\n",
    "\n",
    "    train_size = (int)(len(partition) * 0.7)\n",
    "    train_data = partition[:train_size]\n",
    "    test_data = partition[train_size - HISTORICAL_DATA_WINDOW - FUTURE_PREDICTION_WINDOW + 1:]\n",
    "    data_columns = partition.columns\n",
    "    \n",
    "    if train_data_arr.shape[0] < HISTORICAL_DATA_WINDOW or test_data_arr.shape[0] < HISTORICAL_DATA_WINDOW:\n",
    "        return []\n",
    "    \n",
    "    train_data_frame_X = sliding_window_view(train_data_arr, window_shape = (HISTORICAL_DATA_WINDOW, train_data_arr.shape[1]))\n",
    "    test_data_frame_X = sliding_window_view(test_data_arr, window_shape = (HISTORICAL_DATA_WINDOW, test_data_arr.shape[1]))\n",
    "    train_data_frame_X = np.squeeze(train_data_frame_X)[:-FUTURE_PREDICTION_WINDOW]\n",
    "    test_data_frame_X = np.squeeze(test_data_frame_X)[:-FUTURE_PREDICTION_WINDOW]\n",
    "    train_data_frames_X, test_data_frames_X = train_data_frame_X.copy(), test_data_frame_X.copy()\n",
    "    for frame in train_data_frames_X:\n",
    "        train_frames_X.append(pd.DataFrame(frame, columns=data_columns))\n",
    "    for frame in test_data_frames_X:\n",
    "        test_frames_X.append(pd.DataFrame(frame, columns=data_columns))\n",
    "\n",
    "    train_data_frame_Y = sliding_window_view(train_data_arr, window_shape = (FUTURE_PREDICTION_WINDOW, train_data_arr.shape[1]))\n",
    "    test_data_frame_Y = sliding_window_view(test_data_arr, window_shape = (FUTURE_PREDICTION_WINDOW, test_data_arr.shape[1]))\n",
    "    train_data_frame_Y = np.squeeze(train_data_frame_Y)[HISTORICAL_DATA_WINDOW:]\n",
    "    test_data_frame_Y = np.squeeze(test_data_frame_Y)[HISTORICAL_DATA_WINDOW:]\n",
    "    train_data_frames_Y, test_data_frames_Y = train_data_frame_Y.copy(), test_data_frame_Y.copy()\n",
    "    for frame in train_data_frames_Y:\n",
    "        train_frames_Y.append(pd.DataFrame(frame, columns=data_columns))\n",
    "    for frame in test_data_frames_Y:\n",
    "        test_frames_Y.append(pd.DataFrame(frame, columns=data_columns))   \n",
    "    \n",
    "    \n",
    "    embedding_columns = [\"keyword_length\", \"keyword_num_words\", \"budget\", \"matchType\", \"country_code\", \"campaign_type\",\n",
    "                         \"targeting_type\", \"budget_type\", \"adFormat\", \"tactic\", \"costType\"]\n",
    "\n",
    "    for i in range(len(train_frames_X)):\n",
    "        train_frames_embed.append(train_frames_X[i].loc[0][embedding_columns])\n",
    "        train_frames_X[i].drop(columns=embedding_columns, inplace=True)\n",
    "\n",
    "    for i in range(len(test_frames_X)):\n",
    "        test_frames_embed.append(test_frames_X[i].loc[0][embedding_columns])\n",
    "        test_frames_X[i].drop(columns=embedding_columns, inplace=True)\n",
    "\n",
    "    for i in range(len(train_frames_X)):\n",
    "        train_frames_X[i].drop(columns=[\"keywordId\", \"date\"], inplace=True)\n",
    "        train_frames_Y[i].drop(columns=embedding_columns, inplace=True)\n",
    "        train_frames_Y[i].drop(\n",
    "            columns=[\"keywordId\", \"date\", \"year\", \"month\", \"day\", \"dayoftheweek\", \"clicks\", \"impressions\", \"orders\",\n",
    "                     \"campaign_sales_perc\", \"campaign_spend_perc\", \"account_sales_perc\", \"account_spend_perc\"],\n",
    "            inplace=True)\n",
    "\n",
    "    for i in range(len(test_frames_X)):\n",
    "        test_frames_X[i].drop(columns=[\"keywordId\", \"date\"], inplace=True)\n",
    "        test_frames_Y[i].drop(columns=embedding_columns, inplace=True)\n",
    "        test_frames_Y[i].drop(\n",
    "            columns=[\"keywordId\", \"date\", \"year\", \"month\", \"day\", \"dayoftheweek\", \"clicks\", \"impressions\", \"orders\",\n",
    "                     \"campaign_sales_perc\", \"campaign_spend_perc\", \"account_sales_perc\", \"account_spend_perc\"],\n",
    "            inplace=True)\n",
    "\n",
    "    for i in range(len(train_frames_Y)):\n",
    "        train_frames_decoder_input.append(train_frames_Y[i][\"cpc\"])\n",
    "        train_frames_Y[i].drop(columns=[\"cpc\"], inplace=True)\n",
    "\n",
    "    for i in range(len(test_frames_Y)):\n",
    "        test_frames_decoder_input.append(test_frames_Y[i][\"cpc\"])\n",
    "        test_frames_Y[i].drop(columns=[\"cpc\"], inplace=True)\n",
    "\n",
    "    train_frames_X, train_frames_Y = np.array(train_frames_X), np.array(train_frames_Y)\n",
    "    test_frames_X, test_frames_Y = np.array(test_frames_X), np.array(test_frames_Y)\n",
    "    train_frames_embed, test_frames_embed = np.array(train_frames_embed), np.array(test_frames_embed)\n",
    "    train_frames_decoder_input, test_frames_decoder_input = np.array(train_frames_decoder_input), np.array(\n",
    "        test_frames_decoder_input)\n",
    "\n",
    "    if not os.path.exists(train_frames_x_dir):\n",
    "        os.makedirs(train_frames_x_dir)\n",
    "    if not os.path.exists(test_frames_x_dir):\n",
    "        os.makedirs(test_frames_x_dir)\n",
    "    if not os.path.exists(train_frames_y_dir):\n",
    "        os.makedirs(train_frames_y_dir)\n",
    "    if not os.path.exists(test_frames_y_dir):\n",
    "        os.makedirs(test_frames_y_dir)\n",
    "    if not os.path.exists(train_frames_embed_dir):\n",
    "        os.makedirs(train_frames_embed_dir)\n",
    "    if not os.path.exists(test_frames_embed_dir):\n",
    "        os.makedirs(test_frames_embed_dir)\n",
    "    if not os.path.exists(train_frames_decoder_input_dir):\n",
    "        os.makedirs(train_frames_decoder_input_dir)\n",
    "    if not os.path.exists(test_frames_decoder_input_dir):\n",
    "        os.makedirs(test_frames_decoder_input_dir)\n",
    "\n",
    "    np.save(os.path.join(train_frames_x_dir, f\"par_{split_index}.npy\"), train_frames_X)\n",
    "    np.save(os.path.join(test_frames_x_dir, f\"par_{split_index}.npy\"), test_frames_X)\n",
    "    np.save(os.path.join(train_frames_y_dir, f\"par_{split_index}.npy\"), train_frames_Y)\n",
    "    np.save(os.path.join(test_frames_y_dir, f\"par_{split_index}.npy\"), test_frames_Y)\n",
    "    np.save(os.path.join(train_frames_embed_dir, f\"par_{split_index}.npy\"), train_frames_X)\n",
    "    np.save(os.path.join(test_frames_embed_dir, f\"par_{split_index}.npy\"), test_frames_X)\n",
    "    np.save(os.path.join(train_frames_decoder_input_dir, f\"par_{split_index}.npy\"), train_frames_Y)\n",
    "    np.save(os.path.join(test_frames_decoder_input_dir, f\"par_{split_index}.npy\"), test_frames_Y)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"app inputs and outputs\")\n",
    "    parser.add_argument(\"--s3_input_bucket\", type=str, help=\"s3 input bucket\")\n",
    "    parser.add_argument(\"--s3_output_bucket\", type=str, help=\"s3 output bucket\")\n",
    "    args,_ = parser.parse_known_args()\n",
    "    \n",
    "    save_bucket_name = args.s3_output_bucket\n",
    "    spark = SparkSession.builder.appName(\"PySparkApp\").getOrCreate()\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket=args.s3_input_bucket, Key='processed_training_data.csv')\n",
    "    dataset = pd.read_csv(obj['Body'], nrows=10)\n",
    "    data_columns = dataset.columns\n",
    "    spark_df = spark.createDataFrame(dataset)\n",
    "    \n",
    "    # Convert Spark DataFrame to Pandas DataFrame\n",
    "    pandas_df = spark_df.toPandas()\n",
    "\n",
    "    # Convert Pandas DataFrame back to Spark DataFrame and repartition\n",
    "    spark_df = spark.createDataFrame(pandas_df)\n",
    "    spark_df = spark_df.repartition(spark_df.rdd.getNumPartitions())\n",
    "\n",
    "    # Apply the function to each partition using Spark\n",
    "    spark_df.rdd.mapPartitionsWithIndex(create_training_frames).collect()\n",
    "    \n",
    "    # Apply the function to each partition using Spark\n",
    "    spark.sparkContext.parallelize(partitions).mapPartitionsWithIndex(create_training_frames).collect()\n",
    "    \n",
    "    # Upload the resulting files to S3\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    def upload_pickle(data, bucket, key):\n",
    "        my_array_data = io.BytesIO()\n",
    "        pickle.dump(data, my_array_data)\n",
    "        my_array_data.seek(0)\n",
    "        s3_client.upload_fileobj(my_array_data, bucket, key)\n",
    "        \n",
    "    files = sorted(glob.glob(train_frames_x_dir + '/*.npy'))\n",
    "    train_frames_X = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(train_frames_X, save_bucket_name, \"train_frames_x.pkl\")\n",
    "\n",
    "    files = sorted(glob.glob(train_frames_y_dir + '/*.npy'))\n",
    "    train_frames_Y = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(train_frames_Y, save_bucket_name, \"train_frames_y.pkl\")\n",
    "\n",
    "    files = sorted(glob.glob(train_frames_embed_dir + '/*.npy'))\n",
    "    train_frames_embed = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(train_frames_embed, save_bucket_name, \"train_frames_embed.pkl\")\n",
    "\n",
    "    files = sorted(glob.glob(train_frames_decoder_input_dir + '/*.npy'))\n",
    "    train_frames_decoder_input = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(train_frames_decoder_input, save_bucket_name, \"train_frames_decoder_input.pkl\")\n",
    "\n",
    "    files = sorted(glob.glob(test_frames_x_dir + '/*.npy'))\n",
    "    test_frames_X = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(test_frames_X, save_bucket_name, \"test_frames_x.pkl\")\n",
    "\n",
    "    files = sorted(glob.glob(test_frames_y_dir + '/*.npy'))\n",
    "    test_frames_Y = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(test_frames_Y, save_bucket_name, \"test_frames_y.pkl\")\n",
    "\n",
    "    files = sorted(glob.glob(test_frames_embed_dir + '/*.npy'))\n",
    "    test_frames_embed = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(test_frames_embed, save_bucket_name, \"test_frames_embed.pkl\")\n",
    "\n",
    "    files = sorted(glob.glob(test_frames_decoder_input_dir + '/*.npy'))\n",
    "    test_frames_decoder_input = np.concatenate([np.load(f) for f in files], axis=0)\n",
    "    upload_pickle(test_frames_decoder_input, save_bucket_name, \"test_frames_decoder_input.pkl\")\n",
    "\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d150fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import FrameworkProcessor\n",
    "#sklearn_processor = SKLearnProcessor(\n",
    "#    framework_version=\"0.20.0\", \n",
    "#    role=role, \n",
    "#    instance_type=\"ml.t3.medium\", \n",
    "#    instance_count=2,\n",
    "#    max_runtime_in_seconds=1200,\n",
    "#    sagemaker_session = sagemaker_session,\n",
    "#)\n",
    "est_cls = sagemaker.sklearn.estimator.SKLearn\n",
    "framework_version_str = \"0.20.0\"\n",
    "\n",
    "script_processor = FrameworkProcessor(\n",
    "    role=role,\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    estimator_cls=est_cls,\n",
    "    framework_version=framework_version_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01702087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_test = \"./sklearn_test\"\n",
    "if not os.path.exists(sklearn_test):\n",
    "    os.makedirs(sklearn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor.run(\n",
    "    code=\"preprocess.py\",\n",
    "    #inputs=[ProcessingInput(source=df, destination=\"/opt/ml/processing/sklearn_test\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4797e076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploaded None to s3://sagemaker-eu-west-1-321097665711/sklearn-2023-07-20-04-15-05-452/source/sourcedir.tar.gz\n",
      "Uploaded None to s3://sagemaker-eu-west-1-321097665711/sklearn-2023-07-20-04-15-05-452/source/sourcedir.tar.gz\n",
      "runproc.sh uploaded to s3://sagemaker-eu-west-1-321097665711/sklearn-2023-07-20-04-15-05-452/source/runproc.sh\n",
      "runproc.sh uploaded to s3://sagemaker-eu-west-1-321097665711/sklearn-2023-07-20-04-15-05-452/source/runproc.sh\n",
      "Creating processing-job with name sklearn-2023-07-20-04-15-05-452\n",
      "Creating processing-job with name sklearn-2023-07-20-04-15-05-452\n",
      "INFO:sagemaker:Creating processing-job with name sklearn-2023-07-20-04-15-05-452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "........................................................................\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"preprocess.py\", line 200, in <module>\n",
      "    main()\n",
      "  File \"preprocess.py\", line 129, in main\n",
      "    parser = argparse.ArgumentParser(description=\"app inputs and outputs\")\u001b[0m\n",
      "\u001b[34mNameError: name 'argparse' is not defined\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job sklearn-2023-07-20-04-15-05-452: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProcessingInput, ProcessingOutput\n\u001b[0;32m----> 3\u001b[0m \u001b[43mscript_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreprocess.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#source_dir=\"code\",\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#inputs=[ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\")],\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#outputs=[\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#    ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\"),\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#    ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#],\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#arguments=[\"--train-test-split-ratio\", \"0.2\"],\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m script_processor_job_description \u001b[38;5;241m=\u001b[39m script_processor\u001b[38;5;241m.\u001b[39mjobs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(script_processor_job_description)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/processing.py:1771\u001b[0m, in \u001b[0;36mFrameworkProcessor.run\u001b[0;34m(self, code, source_dir, dependencies, git_config, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m s3_runproc_sh, inputs, job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pack_and_upload_code(\n\u001b[1;32m   1767\u001b[0m     code, source_dir, dependencies, git_config, job_name, inputs, kms_key\n\u001b[1;32m   1768\u001b[0m )\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;66;03m# Submit a processing job.\u001b[39;00m\n\u001b[0;32m-> 1771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_runproc_sh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/processing.py:688\u001b[0m, in \u001b[0;36mScriptProcessor.run\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/processing.py:1113\u001b[0m, in \u001b[0;36mProcessingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Waits for the processing job to complete.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    logs (bool): Whether to show the logs produced by the job (default: True).\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs:\n\u001b[0;32m-> 1113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_processing_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_processing_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:4890\u001b[0m, in \u001b[0;36mSession.logs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4887\u001b[0m             state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE\n\u001b[1;32m   4889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4890\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4891\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   4892\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:6736\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   6731\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   6732\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6733\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6734\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6735\u001b[0m     )\n\u001b[0;32m-> 6736\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6737\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6738\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6739\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6740\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job sklearn-2023-07-20-04-15-05-452: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor.run(\n",
    "    code=\"preprocess.py\",\n",
    "    #source_dir=\"code\",\n",
    "    #inputs=[ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\")],\n",
    "    #outputs=[\n",
    "    #    ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\"),\n",
    "    #    ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\n",
    "    #],\n",
    "    #arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acded4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
